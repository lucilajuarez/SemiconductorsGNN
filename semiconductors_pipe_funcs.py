# -*- coding: utf-8 -*-
"""semiconductors_pipe_funcs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K8AWAobsibnpn00dR8VZZDhASOzfRJCM
"""

import torch
import numpy as np
import pandas as pd
import random
from torch_geometric.data import Data

def set_seed(seed=42):
  """Set all seeds to seed value (default=42)"""
  torch.manual_seed(seed)
  np.random.seed(seed)
  random.seed(seed)
  torch.cuda.manual_seed(seed)
  torch.backends.cudnn.deterministic = True
  torch.backends.cudnn.benchmark = False

def dtype_2check(data):
    """Ensures all relevant tensors in a PyG Data object have the right data type."""
    if hasattr(data, "x") and data.x is not None:
        data.x = data.x.float()
    if hasattr(data, "edge_attr") and data.edge_attr is not None:
        data.edge_attr = data.edge_attr.float()
    if hasattr(data, "graph_attr") and data.graph_attr is not None:
        data.graph_attr = data.graph_attr.float()
    if hasattr(data, "y") and data.y is not None and data.y.dtype == torch.float64:
        data.y = data.y.float()
    if hasattr(data, "edge_index") and data.edge_index is not None:
        data.edge_index = data.edge_index.long()
    return data

def unify_xyz_shape(n_at, vec, latt_vec, xyz):
    """Extends the supercell size to 240 atoms (least common multiple among the sizes) creating new atomic coordinates
    according to the lattice vectors. Notice that if you use this function you need to rescale the lattice in the graph attributes database"""

    xyz.append(vec)
    xyz.append(vec + latt_vec[0])
    xyz.append(vec + latt_vec[1])

    if n_at < 80:
        xyz.append(vec + latt_vec[0] + latt_vec[1])
    if n_at < 60:
        xyz.append(vec + 2.0*latt_vec[0])
        xyz.append(vec + 2.0*latt_vec[1])
    if n_at < 40:
        xyz.append(vec + 2.0*latt_vec[0] + latt_vec[1])
        xyz.append(vec + latt_vec[0] + 2.0*latt_vec[1])
    if n_at < 30:
        xyz.append(vec + 2.0*latt_vec[0] + 2.0*latt_vec[1])
        xyz.append(vec + latt_vec[2])
        xyz.append(vec + latt_vec[0] + latt_vec[2])
        xyz.append(vec + latt_vec[1] + latt_vec[2])
    if n_at < 20:
        xyz.append(vec + latt_vec[0] + latt_vec[1] + latt_vec[2])
        xyz.append(vec + 2.0*latt_vec[0] + latt_vec[1] + latt_vec[2])
        xyz.append(vec + latt_vec[0] + 2.0*latt_vec[1] + latt_vec[2])
        xyz.append(vec + 2.0*latt_vec[0] + 2.0*latt_vec[1] + latt_vec[2])
        xyz.append(vec + latt_vec[0] + 2.0*latt_vec[2])
        xyz.append(vec + latt_vec[1] + 2.0*latt_vec[2])
        xyz.append(vec + 2.0*latt_vec[0] + 2.0*latt_vec[2])
        xyz.append(vec + 2.0*latt_vec[1] + 2.0*latt_vec[2])
        xyz.append(vec + latt_vec[0] + latt_vec[1] + 2.0*latt_vec[2])
        xyz.append(vec + 2.0*latt_vec[0] + latt_vec[1] + 2.0*latt_vec[2])
        xyz.append(vec + latt_vec[0] + 2.0*latt_vec[1] + 2.0*latt_vec[2])
        xyz.append(vec + 2.0*latt_vec[0] + 2.0*latt_vec[1] + 2.0*latt_vec[2])

    return xyz

def get_xyz_tensors(database):
    """Gets the atom elements and xyz coordinates from geometry files in train and test directories and creates
    numpy array of one-hot encoding element followed by its x, y, z coordinates. It uses unify_xyz_shape fuction
    to add atoms according to the extended supercell. Returns an array of of arrays (one per structure in the directory)"""

    ids  = database.index.values
    if ids.size > 1000:
        path = "/train/{}/geometry.xyz"
    else: path = "/test/{}/geometry.xyz"

    XYZ_arrays = []

    for i in ids:
        file = path.format(i)

        xyz = []
        latt_vec = []

        n_at = sum(1 for _ in open(file)) - 6

        with open(file) as f:
            for line in f.readlines():

                if line.rfind("atom")==-1 and line.rfind("lattice_vector")==-1: continue

                x = line.split(' ')

                ## SAVE LATTICE VECTORS
                if line.rfind("lattice_vector")!=-1:
                    vec = np.array([0, 0, 0, 0, 0, 0, x[1], x[2], x[3] ], dtype=float)
                    latt_vec.append(vec)

                ### SAVE XYZ COORDS
                if line.rfind("Al")!=-1:
                    vec = np.array([13, 1.61, 1, 0, 0, 0 , x[1], x[2], x[3] ], dtype=float)  ### Atomic number, electronegativity, element one-hot encoding (4), x, y, z coords.
                    xyz = unify_xyz_shape(n_at=n_at, vec=vec, latt_vec=latt_vec, xyz=xyz)

                if line.rfind("Ga")!=-1:
                    vec = np.array([31, 1.81, 0, 1, 0, 0 , x[1], x[2], x[3] ], dtype=float)
                    xyz = unify_xyz_shape(n_at=n_at, vec=vec, latt_vec=latt_vec, xyz=xyz)

                if line.rfind("In")!=-1:
                    vec = np.array([49, 1.78, 0, 0, 1, 0 , x[1], x[2], x[3] ], dtype=float)
                    xyz = unify_xyz_shape(n_at=n_at, vec=vec, latt_vec=latt_vec, xyz=xyz)

                if line.rfind("O") !=-1:
                    vec = np.array([16, 3.44, 0, 0, 0, 1 , x[1], x[2], x[3] ], dtype=float)
                    xyz = unify_xyz_shape(n_at=n_at, vec=vec, latt_vec=latt_vec, xyz=xyz)


        XYZ_arrays.append(np.asarray(xyz))


    return np.asarray(XYZ_arrays)

def connectivity(tensor, d_max):
    """Takes in a single xyz array produced by the get_xyz_tensor function and a value d_max for the maximum distance
    between connected atoms. Returns the connectivity set and their corresponding connection weights"""

    sample_size = tensor.shape[0]

    connectivity_set = []
    connection_weights = []

    for i in range(sample_size):
        for j in range(sample_size):

            v1 = tensor[i][-3:]
            v2 = tensor[j][-3:]

            aa = 0.01*tensor[i][0]*tensor[j][0]  ### Scaled product of atomic numbers

            diff = v1 - v2
            distance = np.sqrt(np.dot(diff, diff))

            if distance > 0.0 and distance < d_max:
                connectivity_set.append(np.array([i,j], dtype=np.int64))
                connectivity_set.append(np.array([j,i], dtype=np.int64))
                connection_weights.append(np.array(1.0/distance**2))
                connection_weights.append(np.array(1.0/distance**2))

    return np.asarray(connectivity_set, dtype=np.int64), np.asarray(connection_weights)

def onehot(database, column_name):
    "One-hot-encode column_name as separate columns"

    vals = database[column_name].unique()
    for i in vals:
        tof = database[column_name] == i
        database["{}_{}".format(column_name,i)] = tof*1.0

    database.drop(column_name, axis=1, inplace=True)

    return database

def rescale_lattice(row):
    'Rescale lattice vectors in the database according to the unify_xyz_shape function'

    if row.Natoms == 80 or row.Natoms == 60:
        row.l1 = 2.0*row.l1
        row.l2 = 2.0*row.l2
    if row.Natoms == 40 or row.Natoms == 30:
        row.l1 = 3.0*row.l1
        row.l2 = 3.0*row.l2
    if row.Natoms ==20 or row.Natoms == 10:
        row.l1 = 3.0*row.l1
        row.l2 = 3.0*row.l2
        row.l3 = 3.0*row.l3

    return row

def my_pipeline(data: pd.DataFrame):
  """ Takes the original pd.Dataframe object train or test, renames its columns, one-hot encodes the spacegroup, rescales the lattice vectors,
  removes unnecessary columns and returns curated graph features X_data and targets y_data if avaliable (returns y_data None for test)"""

  data.rename(columns={ 'number_of_total_atoms' : 'Natoms', 'percent_atom_al' : 'x_Al',
                       'percent_atom_ga' : 'x_Ga', 'percent_atom_in' : 'x_In','lattice_vector_1_ang' : 'l1',
                        'lattice_vector_2_ang' : 'l2','lattice_vector_3_ang' : 'l3',
                        'lattice_angle_alpha_degree' : 'a','lattice_angle_beta_degree' : 'b',
                        'lattice_angle_gamma_degree' : 'g'}, inplace=True)


  data = onehot( data, "spacegroup" )
  data.drop(['a'], axis=1, inplace=True)
  data.drop(['b'], axis=1, inplace=True)
  data.drop(['g'], axis=1, inplace=True)

  if 'formation_energy_ev_natom' in data.columns and "bandgap_energy_ev" in data.columns:

    data.rename(columns={'formation_energy_ev_natom' : 'E','bandgap_energy_ev' : 'Bandgap'}, inplace = True)

    X_data = data
    y_data = X_data[['E','Bandgap']]
    y_data['Bandgap'] = 0.1*y_data['Bandgap']

    X_data.drop(['E'], axis=1, inplace=True)
    X_data.drop(['Bandgap'], axis=1, inplace=True)

  else:

    X_data = data
    y_data = None

  X_data.apply(rescale_lattice, axis='columns')
  X_data["l1"] = 0.01*X_data["l1"]
  X_data["l2"] = 0.01*X_data["l2"]
  X_data["l3"] = 0.01*X_data["l3"]

  X_data.drop(['Natoms'], axis=1, inplace=True)


  return X_data, y_data

def create_datalist(X,y, d_max=4.0):
  """Takes in a curated pd.DataFrame of graph attributes X and targets y and an optional value in Angstroms
  for the maximum distance of connection between atoms d_max (default set to d_max = 4.0). It uses the functions get_xyz_tensors
  and connectivity, and returns a data list of pythorch geometric Data objects with node feature vector x,
  edge_index, edge_weight, graph attributes and y values if available (it also works for train and test)"""

  print("creating list of Data objects using d_max={}".format(d_max))

  full_tensor = get_xyz_tensors(X)

  data_list = []

  for i in range(full_tensor.shape[0]):

      ## GRAPH FEATURES
      graph_attr = torch.tensor([X.iloc[i]],dtype=torch.float32)

      if y is not None:
        ys = torch.tensor([y.iloc[i]],dtype=torch.float32)

      ## NODE FEATURES
      my_tensor = full_tensor[i]
      element_encoded = torch.from_numpy(my_tensor[:,:-3]).float()

      ## EDGE FEATURES
      c_set, c_dist = connectivity(my_tensor, d_max)
      edge_index = torch.from_numpy(c_set).T.long()
      edge_weight = torch.from_numpy(c_dist).float()

      if y is not None:
        data = Data(x= element_encoded, edge_index= edge_index, edge_weight= edge_weight, graph_attr= graph_attr, y= ys)
      else:
        data = Data(x= element_encoded, edge_index= edge_index, edge_weight= edge_weight, graph_attr= graph_attr)

      data = dtype_2check(data)

      data_list.append(data)

  return data_list